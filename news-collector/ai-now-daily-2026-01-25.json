[
  {
    "title": "Apple will reportedly unveil its Gemini-powered Siri assistant in February",
    "link": "https://techcrunch.com/2026/01/25/apple-will-reportedly-unveil-its-gemini-powered-siri-assistant-in-february/",
    "description": "We’re about to get our first real look at the results of the recently announced AI partnership between Apple and Google.",
    "pubDate": "Sun, 25 Jan 2026 16:56:31 +0000",
    "source": "AI News & Artificial Intelligence | TechCrunch"
  },
  {
    "title": "Tech CEOs boast and bicker about AI at Davos",
    "link": "https://techcrunch.com/2026/01/24/tech-ceos-boast-and-bicker-about-ai-at-davos/",
    "description": "There were times at this week’s meeting of the World Economic Forum when Davos seemed transformed into a high-powered tech conference.",
    "pubDate": "Sat, 24 Jan 2026 20:00:46 +0000",
    "source": "AI News & Artificial Intelligence | TechCrunch"
  },
  {
    "title": "Former Googlers seek to captivate kids with an AI-powered learning app",
    "link": "https://techcrunch.com/2026/01/24/former-google-trio-is-building-an-interactive-ai-powered-learning-app-for-kids/",
    "description": "Sparkli said that education systems often fall behind in teaching modern concepts. The company wants to teach kids about topics like skills design, financial literacy, and entrepreneurship by creating an AI-powered learning \"expedition.\"",
    "pubDate": "Sat, 24 Jan 2026 18:21:21 +0000",
    "source": "AI News & Artificial Intelligence | TechCrunch"
  },
  {
    "title": "A new test for AI labs: Are you even trying to make money?",
    "link": "https://techcrunch.com/2026/01/24/a-new-test-for-ai-labs-are-you-even-trying-to-make-money/",
    "description": "It’s getting hard to tell which AI labs. are actually trying to make money. We created a rating system to help sort it out.",
    "pubDate": "Sat, 24 Jan 2026 17:00:00 +0000",
    "source": "AI News & Artificial Intelligence | TechCrunch"
  },
  {
    "title": "Legal AI giant Harvey acquires Hexus as competition heats up in legal tech",
    "link": "https://techcrunch.com/2026/01/23/legal-ai-giant-harvey-acquires-hexus-as-competition-heats-up-in-legal-tech/",
    "description": "Hexus founder and CEO Sakshi Pratap, who previously held engineering roles at Walmart, Oracle, and Google, tells TechCrunch that her San Francisco-based team has already joined Harvey, while the startup's India-based engineers will come onboard once Harvey establishes a Bangalore office.",
    "pubDate": "Sat, 24 Jan 2026 05:27:22 +0000",
    "source": "AI News & Artificial Intelligence | TechCrunch"
  },
  {
    "title": "Anthropic’s usage stats paint a detailed picture of AI success",
    "link": "https://www.artificialintelligence-news.com/news/anthropic-report-economic-index-summary-key-points-2026/",
    "description": "Anthropic’s Economic Index offers a look at how organisations and individuals are actually using large language models. The report contains the company’s analysis of a million consumer interactions on Claude.ai, plus a million enterprise API calls, all dated from November 2025. The report notes that its figures are based on observations, rather than, for example, […]\nThe post Anthropic’s usage stats paint a detailed picture of AI success appeared first on AI News.",
    "pubDate": "Fri, 23 Jan 2026 14:21:20 +0000",
    "source": "AI News"
  },
  {
    "title": "Defensive AI and how machine learning strengthens cyber defense",
    "link": "https://www.artificialintelligence-news.com/news/defensive-ai-and-how-machine-learning-strengthens-cyber-defense/",
    "description": "Cyber threats don’t follow predictable patterns, forcing security teams to rethink how protection works at scale. Defensive AI is emerging as a practical response, combining machine learning with human oversight. Cybersecurity rarely fails because teams lack tools. It fails because threats move faster than detection can keep pace. As digital systems expand, attackers adapt in […]\nThe post Defensive AI and how machine learning strengthens cyber defense appeared first on AI News.",
    "pubDate": "Fri, 23 Jan 2026 10:15:58 +0000",
    "source": "AI News"
  },
  {
    "title": "Controlling AI agent sprawl: The CIO’s guide to governance",
    "link": "https://www.artificialintelligence-news.com/news/controlling-ai-agent-sprawl-cio-guide-to-governance/",
    "description": "Corporate networks are filling up with AI agents, creating a governance blind spot for leaders managing multi-cloud infrastructures. As distinct business units race to adopt generative technologies, CIOs especially find their ecosystems populated by fragmented and unmonitored assets. This mirrors the shadow IT challenges of the cloud era, but involves autonomous actors capable of executing […]\nThe post Controlling AI agent sprawl: The CIO’s guide to governance appeared first on AI News.",
    "pubDate": "Thu, 22 Jan 2026 17:00:04 +0000",
    "source": "AI News"
  },
  {
    "title": "Gates Foundation and OpenAI test AI in African healthcare",
    "link": "https://www.artificialintelligence-news.com/news/gates-foundation-and-openai-test-ai-in-african-healthcare/",
    "description": "Primary healthcare systems across parts of Africa are under growing strain, caught between rising demand, chronic staff shortages, and shrinking international aid budgets. In that context, AI is being tested in healthcare less as a breakthrough technology and more as a way to keep basic services running. According to reporting by Reuters, the Gates Foundation […]\nThe post Gates Foundation and OpenAI test AI in African healthcare appeared first on AI News.",
    "pubDate": "Thu, 22 Jan 2026 10:00:00 +0000",
    "source": "AI News"
  },
  {
    "title": "Balancing AI cost efficiency with data sovereignty",
    "link": "https://www.artificialintelligence-news.com/news/balancing-ai-cost-efficiency-with-data-sovereignty/",
    "description": "AI cost efficiency and data sovereignty are at odds, forcing a rethink of enterprise risk frameworks for global organisations. For over a year, the generative AI narrative focused on a race for capability, often measuring success by parameter counts and flawed benchmark scores. Boardroom conversations, however, are undergoing a necessary correction. While the allure of […]\nThe post Balancing AI cost efficiency with data sovereignty appeared first on AI News.",
    "pubDate": "Wed, 21 Jan 2026 10:51:23 +0000",
    "source": "AI News"
  },
  {
    "title": "Railway secures $100 million to challenge AWS with AI-native cloud infrastructure",
    "link": "https://venturebeat.com/infrastructure/railway-secures-usd100-million-to-challenge-aws-with-ai-native-cloud",
    "description": "Railway, a San Francisco-based cloud platform that has quietly amassed two million developers without spending a dollar on marketing, announced Thursday that it raised $100 million in a Series B funding round, as surging demand for artificial intelligence applications exposes the limitations of legacy cloud infrastructure.\nTQ Ventures led the round, with participation from FPV Ventures, Redpoint, and Unusual Ventures. The investment values Railway as one of the most significant infrastructure startups to emerge during the AI boom, capitalizing on developer frustration with the complexity and cost of traditional platforms like Amazon Web Services and Google Cloud.\n\"As AI models get better at writing code, more and more people are asking the age-old question: where, and how, do I run my applications?\" said Jake Cooper, Railway's 28-year-old founder and chief executive, in an exclusive interview with VentureBeat. \"The last generation of cloud primitives were slow and outdated, and now with AI moving everything faster, teams simply can't keep up.\"\nThe funding is a dramatic acceleration for a company that has charted an unconventional path through the cloud computing industry. Railway raised just $24 million in total before this round, including a $20 million Series A from Redpoint in 2022. The company now processes more than 10 million deployments monthly and handles over one trillion requests through its edge network — metrics that rival far larger and better-funded competitors.\nWhy three-minute deploy times have become unacceptable in the age of AI coding assistants\nRailway's pitch rests on a simple observation: the tools developers use to deploy and manage software were designed for a slower era. A standard build-and-deploy cycle using Terraform, the industry-standard infrastructure tool, takes two to three minutes. That delay, once tolerable, has become a critical bottleneck as AI coding assistants like Claude, ChatGPT, and Cursor can generate working code in seconds.\n\"When godly intelligence is on tap and can solve any problem in three seconds, those amalgamations of systems become bottlenecks,\" Cooper told VentureBeat. \"What was really cool for humans to deploy in 10 seconds or less is now table stakes for agents.\"\nThe company claims its platform delivers deployments in under one second — fast enough to keep pace with AI-generated code. Customers report a tenfold increase in developer velocity and up to 65 percent cost savings compared to traditional cloud providers.\nThese numbers come directly from enterprise clients, not internal benchmarks. Daniel Lobaton, chief technology officer at G2X, a platform serving 100,000 federal contractors, measured deployment speed improvements of seven times faster and an 87 percent cost reduction after migrating to Railway. His infrastructure bill dropped from $15,000 per month to approximately $1,000.\n\"The work that used to take me a week on our previous infrastructure, I can do in Railway in like a day,\" Lobaton said. \"If I want to spin up a new service and test different architectures, it would take so long on our old setup. In Railway I can launch six services in two minutes.\"\nInside the controversial decision to abandon Google Cloud and build data centers from scratch\nWhat distinguishes Railway from competitors like Render and Fly.io is the depth of its vertical integration. In 2024, the company made the unusual decision to abandon Google Cloud entirely and build its own data centers, a move that echoes the famous Alan Kay maxim: \"People who are really serious about software should make their own hardware.\"\n\"We wanted to design hardware in a way where we could build a differentiated experience,\" Cooper said. \"Having full control over the network, compute, and storage layers lets us do really fast build and deploy loops, the kind that allows us to move at 'agentic speed' while staying 100 percent the smoothest ride in town.\"\nThe approach paid dividends during recent widespread outages that affected major cloud providers — Railway remained online throughout.\nThis soup-to-nuts control enables pricing that undercuts the hyperscalers by roughly 50 percent and newer cloud startups by three to four times. Railway charges by the second for actual compute usage: $0.00000386 per gigabyte-second of memory, $0.00000772 per vCPU-second, and $0.00000006 per gigabyte-second of storage. There are no charges for idle virtual machines — a stark contrast to the traditional cloud model where customers pay for provisioned capacity whether they use it or not.\n\"The conventional wisdom is that the big guys have economies of scale to offer better pricing,\" Cooper noted. \"But when they're charging for VMs that usually sit idle in the cloud, and we've purpose-built everything to fit much more density on these machines, you have a big opportunity.\"\nHow 30 employees built a platform generating tens of millions in annual revenue\nRailway has achieved its scale with a team of just 30 employees generating tens of millions in annual revenue — a ratio of revenue per employee that would be exceptional even for established software companies. The company grew revenue 3.5 times last year and continues to expand at 15 percent month-over-month.\nCooper emphasized that the fundraise was strategic rather than necessary. \"We're default alive; there's no reason for us to raise money,\" he said. \"We raised because we see a massive opportunity to accelerate, not because we needed to survive.\"\nThe company hired its first salesperson only last year and employs just two solutions engineers. Nearly all of Railway's two million users discovered the platform through word of mouth — developers telling other developers about a tool that actually works.\n\"We basically did the standard engineering thing: if you build it, they will come,\" Cooper recalled. \"And to some degree, they came.\"\nFrom side projects to Fortune 500 deployments: Railway's unlikely corporate expansion\nDespite its grassroots developer community, Railway has made significant inroads into large organizations. The company claims that 31 percent of Fortune 500 companies now use its platform, though deployments range from company-wide infrastructure to individual team projects.\nNotable customers include Bilt, the loyalty program company; Intuit's GoCo subsidiary; TripAdvisor's Cruise Critic; and MGM Resorts. Kernel, a Y Combinator-backed startup providing AI infrastructure to over 1,000 companies, runs its entire customer-facing system on Railway for $444 per month.\n\"At my previous company Clever, which sold for $500 million, I had six full-time engineers just managing AWS,\" said Rafael Garcia, Kernel's chief technology officer. \"Now I have six engineers total, and they all focus on product. Railway is exactly the tool I wish I had in 2012.\"\nFor enterprise customers, Railway offers security certifications including SOC 2 Type 2 compliance and HIPAA readiness, with business associate agreements available upon request. The platform provides single sign-on authentication, comprehensive audit logs, and the option to deploy within a customer's existing cloud environment through a \"bring your own cloud\" configuration.\nEnterprise pricing starts at custom levels, with specific add-ons for extended log retention ($200 monthly), HIPAA BAAs ($1,000), enterprise support with SLOs ($2,000), and dedicated virtual machines ($10,000).\nThe startup's bold strategy to take on Amazon, Google, and a new generation of cloud rivals\nRailway enters a crowded market that includes not only the hyperscale cloud providers—Amazon Web Services, Microsoft Azure, and Google Cloud Platform—but also a growing cohort of developer-focused platforms like Vercel, Render, Fly.io, and Heroku.\nCooper argues that Railway's competitors fall into two camps, neither of which has fully committed to the new infrastructure model that AI demands.\n\"The hyperscalers have two competing systems, and they haven't gone all-in on the new model because their legacy revenue stream is still printing money,\" he observed. \"They have this mammoth pool of cash coming from people who provision a VM, use maybe 10 percent of it, and still pay for the whole thing. To what end are they actually interested in going all the way in on a new experience if they don't really need to?\"\nAgainst startup competitors, Railway differentiates by covering the full infrastructure stack. \"We're not just containers; we've got VM primitives, stateful storage, virtual private networking, automated load balancing,\" Cooper said. \"And we wrap all of this in an absurdly easy-to-use UI, with agentic primitives so agents can move 1,000 times faster.\"\nThe platform supports databases including PostgreSQL, MySQL, MongoDB, and Redis; provides up to 256 terabytes of persistent storage with over 100,000 input/output operations per second; and enables deployment to four global regions spanning the United States, Europe, and Southeast Asia. Enterprise customers can scale to 112 vCPUs and 2 terabytes of RAM per service.\nWhy investors are betting that AI will create a thousand times more software than exists today\nRailway's fundraise reflects broader investor enthusiasm for companies positioned to benefit from the AI coding revolution. As tools like GitHub Copilot, Cursor, and Claude become standard fixtures in developer workflows, the volume of code being written — and the infrastructure needed to run it — is expanding dramatically.\n\"The amount of software that's going to come online over the next five years is unfathomable compared to what existed before — we're talking a thousand times more software,\" Cooper predicted. \"All of that has to run somewhere.\"\nThe company has already integrated directly with AI systems, building what Cooper calls \"loops where Claude can hook in, call deployments, and analyze infrastructure automatically.\" Railway released a Model Context Protocol server in August 2025 that allows AI coding agents to deploy applications and manage infrastructure directly from code editors.\n\"The notion of a developer is melting before our eyes,\" Cooper said. \"You don't have to be an engineer to engineer things anymore — you just need critical thinking and the ability to analyze things in a systems capacity.\"\nWhat Railway plans to do with $100 million and zero marketing experience\nRailway plans to use the new capital to expand its global data center footprint, grow its team beyond 30 employees, and build what Cooper described as a proper go-to-market operation for the first time in the company's five-year history.\n\"One of my mentors said you raise money when you can change the trajectory of the business,\" Cooper explained. \"We've built all the required substrate to scale indefinitely; what's been holding us back is simply talking about it. 2026 is the year we play on the world stage.\"\nThe company's investor roster reads like a who's who of developer infrastructure. Angel investors include Tom Preston-Werner, co-founder of GitHub; Guillermo Rauch, chief executive of Vercel; Spencer Kimball, chief executive of Cockroach Labs; Olivier Pomel, chief executive of Datadog; and Jori Lallo, co-founder of Linear.\nThe timing of Railway's expansion coincides with what many in Silicon Valley view as a fundamental shift in how software gets made. Coding assistants are no longer experimental curiosities — they have become essential tools that millions of developers rely on daily. Each line of AI-generated code needs somewhere to run, and the incumbents, by Cooper's telling, are too wedded to their existing business models to fully capitalize on the moment.\nWhether Railway can translate developer enthusiasm into sustained enterprise adoption remains an open question. The cloud infrastructure market is littered with promising startups that failed to break the grip of Amazon, Microsoft, and Google. But Cooper, who previously worked as a software engineer at Wolfram Alpha, Bloomberg, and Uber before founding Railway in 2020, seems unfazed by the scale of his ambition.\n\"In five years, Railway [will be] the place where software gets created and evolved, period,\" he said. \"Deploy instantly, scale infinitely, with zero friction. That's the prize worth playing for, and there's no bigger one on offer.\"\nFor a company that built a $100 million business by doing the opposite of what conventional startup wisdom dictates — no marketing, no sales team, no venture hype—the real test begins now. Railway spent five years proving that developers would find a better mousetrap on their own. The next five will determine whether the rest of the world is ready to get on board.",
    "pubDate": "Thu, 22 Jan 2026 14:00:00 GMT",
    "source": "AI | VentureBeat"
  },
  {
    "title": "Claude Code costs up to $200 a month. Goose does the same thing for free.",
    "link": "https://venturebeat.com/infrastructure/claude-code-costs-up-to-usd200-a-month-goose-does-the-same-thing-for-free",
    "description": "The artificial intelligence coding revolution comes with a catch: it's expensive.\nClaude Code, Anthropic's terminal-based AI agent that can write, debug, and deploy code autonomously, has captured the imagination of software developers worldwide. But its pricing — ranging from $20 to $200 per month depending on usage — has sparked a growing rebellion among the very programmers it aims to serve.\nNow, a free alternative is gaining traction. Goose, an open-source AI agent developed by Block (the financial technology company formerly known as Square), offers nearly identical functionality to Claude Code but runs entirely on a user's local machine. No subscription fees. No cloud dependency. No rate limits that reset every five hours.\n\"Your data stays with you, period,\" said Parth Sareen, a software engineer who demonstrated the tool during a recent livestream. The comment captures the core appeal: Goose gives developers complete control over their AI-powered workflow, including the ability to work offline — even on an airplane.\nThe project has exploded in popularity. Goose now boasts more than 26,100 stars on GitHub, the code-sharing platform, with 362 contributors and 102 releases since its launch. The latest version, 1.20.1, shipped on January 19, 2026, reflecting a development pace that rivals commercial products.\nFor developers frustrated by Claude Code's pricing structure and usage caps, Goose represents something increasingly rare in the AI industry: a genuinely free, no-strings-attached option for serious work.\n\nAnthropic's new rate limits spark a developer revolt\nTo understand why Goose matters, you need to understand the Claude Code pricing controversy.\nAnthropic, the San Francisco artificial intelligence company founded by former OpenAI executives, offers Claude Code as part of its subscription tiers. The free plan provides no access whatsoever. The Pro plan, at $17 per month with annual billing (or $20 monthly), limits users to just 10 to 40 prompts every five hours — a constraint that serious developers exhaust within minutes of intensive work.\nThe Max plans, at $100 and $200 per month, offer more headroom: 50 to 200 prompts and 200 to 800 prompts respectively, plus access to Anthropic's most powerful model, Claude 4.5 Opus. But even these premium tiers come with restrictions that have inflamed the developer community.\nIn late July, Anthropic announced new weekly rate limits. Under the system, Pro users receive 40 to 80 hours of Sonnet 4 usage per week. Max users at the $200 tier get 240 to 480 hours of Sonnet 4, plus 24 to 40 hours of Opus 4. Nearly five months later, the frustration has not subsided.\nThe problem? Those \"hours\" are not actual hours. They represent token-based limits that vary wildly depending on codebase size, conversation length, and the complexity of the code being processed. Independent analysis suggests the actual per-session limits translate to roughly 44,000 tokens for Pro users and 220,000 tokens for the $200 Max plan.\n\"It's confusing and vague,\" one developer wrote in a widely shared analysis. \"When they say '24-40 hours of Opus 4,' that doesn't really tell you anything useful about what you're actually getting.\"\nThe backlash on Reddit and developer forums has been fierce. Some users report hitting their daily limits within 30 minutes of intensive coding. Others have canceled their subscriptions entirely, calling the new restrictions \"a joke\" and \"unusable for real work.\"\nAnthropic has defended the changes, stating that the limits affect fewer than five percent of users and target people running Claude Code \"continuously in the background, 24/7.\" But the company has not clarified whether that figure refers to five percent of Max subscribers or five percent of all users — a distinction that matters enormously.\nHow Block built a free AI coding agent that works offline\nGoose takes a radically different approach to the same problem.\nBuilt by Block, the payments company led by Jack Dorsey, Goose is what engineers call an \"on-machine AI agent.\" Unlike Claude Code, which sends your queries to Anthropic's servers for processing, Goose can run entirely on your local computer using open-source language models that you download and control yourself.\nThe project's documentation describes it as going \"beyond code suggestions\" to \"install, execute, edit, and test with any LLM.\" That last phrase — \"any LLM\" — is the key differentiator. Goose is model-agnostic by design.\nYou can connect Goose to Anthropic's Claude models if you have API access. You can use OpenAI's GPT-5 or Google's Gemini. You can route it through services like Groq or OpenRouter. Or — and this is where things get interesting — you can run it entirely locally using tools like Ollama, which let you download and execute open-source models on your own hardware.\nThe practical implications are significant. With a local setup, there are no subscription fees, no usage caps, no rate limits, and no concerns about your code being sent to external servers. Your conversations with the AI never leave your machine.\n\"I use Ollama all the time on planes — it's a lot of fun!\" Sareen noted during a demonstration, highlighting how local models free developers from the constraints of internet connectivity.\nWhat Goose can do that traditional code assistants can't\nGoose operates as a command-line tool or desktop application that can autonomously perform complex development tasks. It can build entire projects from scratch, write and execute code, debug failures, orchestrate workflows across multiple files, and interact with external APIs — all without constant human oversight.\nThe architecture relies on what the AI industry calls \"tool calling\" or \"function calling\" — the ability for a language model to request specific actions from external systems. When you ask Goose to create a new file, run a test suite, or check the status of a GitHub pull request, it doesn't just generate text describing what should happen. It actually executes those operations.\nThis capability depends heavily on the underlying language model. Claude 4 models from Anthropic currently perform best at tool calling, according to the Berkeley Function-Calling Leaderboard, which ranks models on their ability to translate natural language requests into executable code and system commands.\nBut newer open-source models are catching up quickly. Goose's documentation highlights several options with strong tool-calling support: Meta's Llama series, Alibaba's Qwen models, Google's Gemma variants, and DeepSeek's reasoning-focused architectures.\nThe tool also integrates with the Model Context Protocol, or MCP, an emerging standard for connecting AI agents to external services. Through MCP, Goose can access databases, search engines, file systems, and third-party APIs — extending its capabilities far beyond what the base language model provides.\nSetting Up Goose with a Local Model\nFor developers interested in a completely free, privacy-preserving setup, the process involves three main components: Goose itself, Ollama (a tool for running open-source models locally), and a compatible language model.\nStep 1: Install Ollama\nOllama is an open-source project that dramatically simplifies the process of running large language models on personal hardware. It handles the complex work of downloading, optimizing, and serving models through a simple interface.\nDownload and install Ollama from ollama.com. Once installed, you can pull models with a single command. For coding tasks, Qwen 2.5 offers strong tool-calling support:\nollama run qwen2.5\nThe model downloads automatically and begins running on your machine.\nStep 2: Install Goose\nGoose is available as both a desktop application and a command-line interface. The desktop version provides a more visual experience, while the CLI appeals to developers who prefer working entirely in the terminal.\nInstallation instructions vary by operating system but generally involve downloading from Goose's GitHub releases page or using a package manager. Block provides pre-built binaries for macOS (both Intel and Apple Silicon), Windows, and Linux.\nStep 3: Configure the Connection\nIn Goose Desktop, navigate to Settings, then Configure Provider, and select Ollama. Confirm that the API Host is set to http://localhost:11434 (Ollama's default port) and click Submit.\nFor the command-line version, run goose configure, select \"Configure Providers,\" choose Ollama, and enter the model name when prompted.\nThat's it. Goose is now connected to a language model running entirely on your hardware, ready to execute complex coding tasks without any subscription fees or external dependencies.\nThe RAM, processing power, and trade-offs you should know about\nThe obvious question: what kind of computer do you need?\nRunning large language models locally requires substantially more computational resources than typical software. The key constraint is memory — specifically, RAM on most systems, or VRAM if using a dedicated graphics card for acceleration.\nBlock's documentation suggests that 32 gigabytes of RAM provides \"a solid baseline for larger models and outputs.\" For Mac users, this means the computer's unified memory is the primary bottleneck. For Windows and Linux users with discrete NVIDIA graphics cards, GPU memory (VRAM) matters more for acceleration.\nBut you don't necessarily need expensive hardware to get started. Smaller models with fewer parameters run on much more modest systems. Qwen 2.5, for instance, comes in multiple sizes, and the smaller variants can operate effectively on machines with 16 gigabytes of RAM.\n\"You don't need to run the largest models to get excellent results,\" Sareen emphasized. The practical recommendation: start with a smaller model to test your workflow, then scale up as needed.\nFor context, Apple's entry-level MacBook Air with 8 gigabytes of RAM would struggle with most capable coding models. But a MacBook Pro with 32 gigabytes — increasingly common among professional developers — handles them comfortably.\nWhy keeping your code off the cloud matters more than ever\nGoose with a local LLM is not a perfect substitute for Claude Code. The comparison involves real trade-offs that developers should understand.\nModel Quality: Claude 4.5 Opus, Anthropic's flagship model, remains arguably the most capable AI for software engineering tasks. It excels at understanding complex codebases, following nuanced instructions, and producing high-quality code on the first attempt. Open-source models have improved dramatically, but a gap persists — particularly for the most challenging tasks.\nOne developer who switched to the $200 Claude Code plan described the difference bluntly: \"When I say 'make this look modern,' Opus knows what I mean. Other models give me Bootstrap circa 2015.\"\nContext Window: Claude Sonnet 4.5, accessible through the API, offers a massive one-million-token context window — enough to load entire large codebases without chunking or context management issues. Most local models are limited to 4,096 or 8,192 tokens by default, though many can be configured for longer contexts at the cost of increased memory usage and slower processing.\nSpeed: Cloud-based services like Claude Code run on dedicated server hardware optimized for AI inference. Local models, running on consumer laptops, typically process requests more slowly. The difference matters for iterative workflows where you're making rapid changes and waiting for AI feedback.\nTooling Maturity: Claude Code benefits from Anthropic's dedicated engineering resources. Features like prompt caching (which can reduce costs by up to 90 percent for repeated contexts) and structured outputs are polished and well-documented. Goose, while actively developed with 102 releases to date, relies on community contributions and may lack equivalent refinement in specific areas.\nHow Goose stacks up against Cursor, GitHub Copilot, and the paid AI coding market\nGoose enters a crowded market of AI coding tools, but occupies a distinctive position.\nCursor, a popular AI-enhanced code editor, charges $20 per month for its Pro tier and $200 for Ultra—pricing that mirrors Claude Code's Max plans. Cursor provides approximately 4,500 Sonnet 4 requests per month at the Ultra level, a substantially different allocation model than Claude Code's hourly resets.\nCline, Roo Code, and similar open-source projects offer AI coding assistance but with varying levels of autonomy and tool integration. Many focus on code completion rather than the agentic task execution that defines Goose and Claude Code.\nAmazon's CodeWhisperer, GitHub Copilot, and enterprise offerings from major cloud providers target large organizations with complex procurement processes and dedicated budgets. They are less relevant to individual developers and small teams seeking lightweight, flexible tools.\nGoose's combination of genuine autonomy, model agnosticism, local operation, and zero cost creates a unique value proposition. The tool is not trying to compete with commercial offerings on polish or model quality. It's competing on freedom — both financial and architectural.\nThe $200-a-month era for AI coding tools may be ending\nThe AI coding tools market is evolving quickly. Open-source models are improving at a pace that continually narrows the gap with proprietary alternatives. Moonshot AI's Kimi K2 and z.ai's GLM 4.5 now benchmark near Claude Sonnet 4 levels — and they're freely available.\nIf this trajectory continues, the quality advantage that justifies Claude Code's premium pricing may erode. Anthropic would then face pressure to compete on features, user experience, and integration rather than raw model capability.\nFor now, developers face a clear choice. Those who need the absolute best model quality, who can afford premium pricing, and who accept usage restrictions may prefer Claude Code. Those who prioritize cost, privacy, offline access, and flexibility have a genuine alternative in Goose.\nThe fact that a $200-per-month commercial product has a zero-dollar open-source competitor with comparable core functionality is itself remarkable. It reflects both the maturation of open-source AI infrastructure and the appetite among developers for tools that respect their autonomy.\nGoose is not perfect. It requires more technical setup than commercial alternatives. It depends on hardware resources that not every developer possesses. Its model options, while improving rapidly, still trail the best proprietary offerings on complex tasks.\nBut for a growing community of developers, those limitations are acceptable trade-offs for something increasingly rare in the AI landscape: a tool that truly belongs to them.\n\nGoose is available for download at github.com/block/goose. Ollama is available at ollama.com. Both projects are free and open source.",
    "pubDate": "Mon, 19 Jan 2026 14:00:00 GMT",
    "source": "AI | VentureBeat"
  },
  {
    "title": "Listen Labs raises $69M after viral billboard hiring stunt to scale AI customer interviews",
    "link": "https://venturebeat.com/technology/listen-labs-raises-usd69m-after-viral-billboard-hiring-stunt-to-scale-ai",
    "description": "Alfred Wahlforss was running out of options. His startup, Listen Labs, needed to hire over 100 engineers, but competing against Mark Zuckerberg's $100 million offers seemed impossible. So he spent $5,000 — a fifth of his marketing budget — on a billboard in San Francisco displaying what looked like gibberish: five strings of random numbers.\nThe numbers were actually AI tokens. Decoded, they led to a coding challenge: build an algorithm to act as a digital bouncer at Berghain, the Berlin nightclub famous for rejecting nearly everyone at the door. Within days, thousands attempted the puzzle. 430 cracked it. Some got hired. The winner flew to Berlin, all expenses paid.\nThat unconventional approach has now attracted $69 million in Series B funding, led by Ribbit Capital with participation from Evantic and existing investors Sequoia Capital, Conviction, and Pear VC. The round values Listen Labs at $500 million and brings its total capital to $100 million. In nine months since launch, the company has grown annualized revenue by 15x to eight figures and conducted over one million AI-powered interviews.\n\n\"When you obsess over customers, everything else follows,\" Wahlforss said in an interview with VentureBeat. \"Teams that use Listen bring the customer into every decision, from marketing to product, and when the customer is delighted, everyone is.\"\nWhy traditional market research is broken, and what Listen Labs is building to fix it\nListen's AI researcher finds participants, conducts in-depth interviews, and delivers actionable insights in hours, not weeks. The platform replaces the traditional choice between quantitative surveys — which provide statistical precision but miss nuance—and qualitative interviews, which deliver depth but cannot scale.\nWahlforss explained the limitation of existing approaches: \"Essentially surveys give you false precision because people end up answering the same question... You can't get the outliers. People are actually not honest on surveys.\" The alternative, one-on-one human interviews, \"gives you a lot of depth. You can ask follow up questions. You can kind of double check if they actually know what they're talking about. And the problem is you can't scale that.\"\nThe platform works in four steps: users create a study with AI assistance, Listen recruits participants from its global network of 30 million people, an AI moderator conducts in-depth interviews with follow-up questions, and results are packaged into executive-ready reports including key themes, highlight reels, and slide decks.\nWhat distinguishes Listen's approach is its use of open-ended video conversations rather than multiple-choice forms. \"In a survey, you can kind of guess what you should answer, and you have four options,\" Wahlforss said. \"Oh, they probably want me to buy high income. Let me click on that button versus an open ended response. It just generates much more honesty.\"\nThe dirty secret of the $140 billion market research industry: rampant fraud\nListen finds and qualifies the right participants in its global network of 30 million people. But building that panel required confronting what Wahlforss called \"one of the most shocking things that we've learned when we entered this industry\"—rampant fraud.\n\"Essentially, there's a financial transaction involved, which means there will be bad players,\" he explained. \"We actually had some of the largest companies, some of them have billions in revenue, send us people who claim to be kind of enterprise buyers to our platform and our system immediately detected, like, fraud, fraud, fraud, fraud, fraud.\"\nThe company built what it calls a \"quality guard\" that cross-references LinkedIn profiles with video responses to verify identity, checks consistency across how participants answer questions, and flags suspicious patterns. The result, according to Wahlforss: \"People talk three times more. They're much more honest when they talk about sensitive topics like politics and mental health.\"\nEmeritus, an online education company that uses Listen, reported that approximately 20% of survey responses previously fell into the fraudulent or low-quality category. With Listen, they reduced this to almost zero. \"We did not have to replace any responses because of fraud or gibberish information,\" said Gabrielli Tiburi, Assistant Manager of Customer Insights at Emeritus.\nHow Microsoft, Sweetgreen, and Chubbies are using AI interviews to build better products\nThe speed advantage has proven central to Listen's pitch. Traditional customer research at Microsoft could take four to six weeks to generate insights. \"By the time we get to them, either the decision has been made or we lose out on the opportunity to actually influence it,\" said Romani Patel, Senior Research Manager at Microsoft.\nWith Listen, Microsoft can now get insights in days, and in many cases, within hours.\nThe platform has already powered several high-profile initiatives. Microsoft used Listen Labs to collect global customer stories for its 50th anniversary celebration. \"We wanted users to share how Copilot is empowering them to bring their best self forward,\" Patel said, \"and we were able to collect those user video stories within a day.\" Traditionally, that kind of work would have taken six to eight weeks.\nSimple Modern, an Oklahoma-based drinkware company, used Listen to test a new product concept. The process took about an hour to write questions, an hour to launch the study, and 2.5 hours to receive feedback from 120 people across the country. \"We went from 'Should we even have this product?' to 'How should we launch it?'\" said Chris Hoyle, the company's Chief Marketing Officer.\nChubbies, the shorts brand, achieved a 24x increase in youth research participation—growing from 5 to 120 participants — by using Listen to overcome the scheduling challenges of traditional focus groups with children. \"There's school, sports, dinner, and homework,\" explained Lauren Neville, Director of Insights and Innovation. \"I had to find a way to hear from them that fit into their schedules.\"\nThe company also discovered product issues through AI interviews that might have gone undetected otherwise. Wahlforss described how the AI \"through conversations, realized there were like issues with the the kids short line, and decided to, like, interview hundreds of kids. And I understand that there were issues in the liner of the shorts and that they were, like, scratchy, quote, unquote, according to the people interviewed.\" The redesigned product became \"a blockbuster hit.\"\nThe Jevons paradox explains why cheaper research creates more demand, not less\nListen Labs is entering a massive but fragmented market. Wahlforss cited research from Andreessen Horowitz estimating the market research industry at roughly $140 billion annually, populated by legacy players — some with more than a billion dollars in revenue — that he believes are vulnerable to disruption.\n\"There are very much existing budget lines that we are replacing,\" Wahlforss said. \"Why we're replacing them is that one, they're super costly. Two, they're kind of stuck in this old paradigm of choosing between a survey or interview, and they also take months to work with.\"\nBut the more intriguing dynamic may be that AI-powered research doesn't just replace existing spending — it creates new demand. Wahlforss invoked the Jevons paradox, an economic principle that occurs when technological advancements make a resource more efficient to use, but increased efficiency leads to increased overall consumption rather than decreased consumption.\n\"What I've noticed is that as something gets cheaper, you don't need less of it. You want more of it,\" Wahlforss explained. \"There's infinite demand for customer understanding. So the researchers on the team can do an order of magnitude more research, and also other people who weren't researchers before can now do that as part of their job.\"\nInside the elite engineering team that built Listen Labs before they had a working toilet\nListen Labs traces its origins to a consumer app that Wahlforss and his co-founder built after meeting at Harvard. \"We built this consumer app that got 20,000 downloads in one day,\" Wahlforss recalled. \"We had all these users, and we were thinking like, okay, what can we do to get to know them better? And we built this prototype of what Listen is today.\"\nThe founding team brings an unusual pedigree. Wahlforss's co-founder \"was the national champion in competitive programming in Germany, and he worked at Tesla Autopilot.\" The company claims that 30% of its engineering team are medalists from the International Olympiad in Informatics — the same competition that produced the founders of Cognition, the AI coding startup.\nThe Berghain billboard stunt generated approximately 5 million views across social media, according to Wahlforss. It reflected the intensity of the talent war in the Bay Area.\n\"We had to do these things because some of our, like early employees, joined the company before we had a working toilet,\" he said. \"But now we fixed that situation.\"\nThe company grew from 5 to 40 employees in 2024 and plans to reach 150 this year. It hires engineers for non-engineering roles across marketing, growth, and operations — a bet that in the AI era, technical fluency matters everywhere.\nSynthetic customers and automated decisions: what Listen Labs is building next\nWahlforss outlined an ambitious product roadmap that pushes into more speculative territory. The company is building \"the ability to simulate your customers, so you can take all of those interviews we've done, and then extrapolate based on that and create synthetic users or simulated user voices.\"\nBeyond simulation, Listen aims to enable automated action based on research findings. \"Can you not just make recommendations, but also create spawn agents to either change things in code or some customer churns? Can you give them a discount and try to bring them back?\"\nWahlforss acknowledged the ethical implications. \"Obviously, as you said, there's kind of ethical concerns there. Of like, automated decision making overall can be bad, but we will have considerable guardrails to make sure that the companies are always in the loop.\"\nThe company already handles sensitive data with care. \"We don't train on any of the data,\" Wahlforss said. \"We will also scrub any sensitive PII automatically so the model can detect that. And there are times when, for example, you work with investors, where if you accidentally mention something that could be material, non public information, the AI can actually detect that and remove any information like that.\"\nHow AI could reshape the future of product development\nPerhaps the most provocative implication of Listen's model is how it could reshape product development itself. Wahlforss described a customer — an Australian startup — that has adopted what amounts to a continuous feedback loop.\n\"They're based in Australia, so they're coding during the day, and then in their night, they're releasing a Listen study with an American audience. Listen validates whatever they built during the day, and they get feedback on that. They can then plug that feedback directly into coding tools like Claude Code and iterate.\"\nThe vision extends Y Combinator's famous dictum — \"write code, talk to users\" — into an automated cycle. \"Write code is now getting automated. And I think like talk to users will be as well, and you'll have this kind of infinite loop where you can start to ship this truly amazing product, almost kind of autonomously.\"\nWhether that vision materializes depends on factors beyond Listen's control — the continued improvement of AI models, enterprise willingness to trust automated research, and whether speed truly correlates with better products. A 2024 MIT study found that 95% of AI pilots fail to move into production, a statistic Wahlforss cited as the reason he emphasizes quality over demos.\n\"I'm constantly have to emphasize like, let's make sure the quality is there and the details are right,\" he said.\nBut the company's growth suggests appetite for the experiment. Microsoft's Patel said Listen has \"removed the drudgery of research and brought the fun and joy back into my work.\" Chubbies is now pushing its founder to give everyone in the company a login. Sling Money, a stablecoin payments startup, can create a survey in ten minutes and receive results the same day.\n\"It's a total game changer,\" said Ali Romero, Sling Money's marketing manager.\nWahlforss has a different phrase for what he's building. When asked about the tension between speed and rigor — the long-held belief that moving fast means cutting corners — he cited Nat Friedman, the former GitHub CEO and Listen investor, who keeps a list of one-liners on his website.\nOne of them: \"Slow is fake.\"\nIt's an aggressive claim for an industry built on methodological caution. But Listen Labs is betting that in the AI era, the companies that listen fastest will be the ones that win. The only question is whether customers will talk back.",
    "pubDate": "Fri, 16 Jan 2026 14:01:00 GMT",
    "source": "AI | VentureBeat"
  },
  {
    "title": "Salesforce rolls out new Slackbot AI agent as it battles Microsoft and Google in workplace AI",
    "link": "https://venturebeat.com/technology/salesforce-rolls-out-new-slackbot-ai-agent-as-it-battles-microsoft-and",
    "description": "Salesforce on Tuesday launched an entirely rebuilt version of Slackbot, the company's workplace assistant, transforming it from a simple notification tool into what executives describe as a fully powered AI agent capable of searching enterprise data, drafting documents, and taking action on behalf of employees.\nThe new Slackbot, now generally available to Business+ and Enterprise+ customers, is Salesforce's most aggressive move yet to position Slack at the center of the emerging \"agentic AI\" movement — where software agents work alongside humans to complete complex tasks. The launch comes as Salesforce attempts to convince investors that artificial intelligence will bolster its products rather than render them obsolete.\n\"Slackbot isn't just another copilot or AI assistant,\" said Parker Harris, Salesforce co-founder and Slack's chief technology officer, in an exclusive interview with Salesforce. \"It's the front door to the agentic enterprise, powered by Salesforce.\"\nFrom tricycle to Porsche: Salesforce rebuilt Slackbot from the ground up\nHarris was blunt about what distinguishes the new Slackbot from its predecessor: \"The old Slackbot was, you know, a little tricycle, and the new Slackbot is like, you know, a Porsche.\"\nThe original Slackbot, which has existed since Slack's early days, performed basic algorithmic tasks — reminding users to add colleagues to documents, suggesting channel archives, and delivering simple notifications. The new version runs on an entirely different architecture built around a large language model and sophisticated search capabilities that can access Salesforce records, Google Drive files, calendar data, and years of Slack conversations.\n\"It's two different things,\" Harris explained. \"The old Slackbot was algorithmic and fairly simple. The new Slackbot is brand new — it's based around an LLM and a very robust search engine, and connections to third-party search engines, third-party enterprise data.\"\nSalesforce chose to retain the Slackbot brand despite the fundamental technical overhaul. \"People know what Slackbot is, and so we wanted to carry that forward,\" Harris said.\nWhy Anthropic's Claude powers the new Slackbot — and which AI models could come next\nThe new Slackbot runs on Claude, Anthropic's large language model, a choice driven partly by compliance requirements. Slack's commercial service operates under FedRAMP Moderate certification to serve U.S. federal government customers, and Harris said Anthropic was \"the only provider that could give us a compliant LLM\" when Slack began building the new system.\nBut that exclusivity won't last. \"We are, this year, going to support additional providers,\" Harris said. \"We have a great relationship with Google. Gemini is incredible — performance is great, cost is great. So we're going to use Gemini for some things.\" He added that OpenAI remains a possibility as well.\nHarris echoed Salesforce CEO Marc Benioff's view that large language models are becoming commoditized: \"You've heard Marc talk about LLMs are commodities, that they're democratized. I call them CPUs.\"\nOn the sensitive question of training data, Harris was unequivocal: Salesforce does not train any models on customer data. \"Models don't have any sort of security,\" he explained. \"If we trained it on some confidential conversation that you and I have, I don't want Carolyn to know — if I train it into the LLM, there is no way for me to say you get to see the answer, but Carolyn doesn't.\"\nInside Salesforce's internal experiment: 80,000 employees tested Slackbot with striking results\nSalesforce has been testing the new Slackbot internally for months, rolling it out to all 80,000 employees. According to Ryan Gavin, Slack's chief marketing officer, the results have been striking: \"It's the fastest adopted product in Salesforce history.\"\nInternal data shows that two-thirds of Salesforce employees have tried the new Slackbot, with 80% of those users continuing to use it regularly. Internal satisfaction rates reached 96% — the highest for any AI feature Slack has shipped. Employees report saving between two and 20 hours per week.\nThe adoption happened largely organically. \"I think it was about five days, and a Canvas was developed by our employees called 'The Most Stealable Slackbot Prompts,'\" Gavin said. \"People just started adding to it organically. I think it's up to 250-plus prompts that are in this Canvas right now.\"\nKate Crotty, a principal UX researcher at Salesforce, found that 73% of internal adoption was driven by social sharing rather than top-down mandates. \"Everybody is there to help each other learn and communicate hacks,\" she said.\nHow Slackbot transforms scattered enterprise data into executive-ready insights\nDuring a product demonstration, Amy Bauer, Slack's product experience designer, showed how Slackbot can synthesize information across multiple sources. In one example, she asked Slackbot to analyze customer feedback from a pilot program, upload an image of a usage dashboard, and have Slackbot correlate the qualitative and quantitative data.\n\"This is where Slackbot really earns its keep for me,\" Bauer explained. \"What it's doing is not just simply reading the image — it's actually looking at the image and comparing it to the insight it just generated for me.\"\nSlackbot can then query Salesforce to find enterprise accounts with open deals that might be good candidates for early access, creating what Bauer called \"a really great justification and plan to move forward.\" Finally, it can synthesize all that information into a Canvas — Slack's collaborative document format — and find calendar availability among stakeholders to schedule a review meeting.\n\"Up until this point, we have been working in a one-to-one capacity with Slackbot,\" Bauer said. \"But one of the benefits that I can do now is take this insight and have it generate this into a Canvas, a shared workspace where I can iterate on it, refine it with Slackbot, or share it out with my team.\"\nRob Seaman, Slack's chief product officer, said the Canvas creation demonstrates where the product is heading: \"This is making a tool call internally to Slack Canvas to actually write, effectively, a shared document. But it signals where we're going with Slackbot — we're eventually going to be adding in additional third-party tool calls.\"\nMrBeast's company became a Slackbot guinea pig—and employees say they're saving 90 minutes a day\nAmong Salesforce's pilot customers is Beast Industries, the parent company of YouTube star MrBeast. Luis Madrigal, the company's chief information officer, joined the launch announcement to describe his experience.\n\"As somebody who has rolled out enterprise technologies for over two decades now, this was practically one of the easiest,\" Madrigal said. \"The plumbing is there. Slack as an implementation, Enterprise Tools — being able to turn on the Slackbot and the Slack AI functionality was as simple as having my team go in, review, do a quick security review.\"\nMadrigal said his security team signed off \"rather quickly\" — unusual for enterprise AI deployments — because Slackbot accesses only the information each individual user already has permission to view. \"Given all the guardrails you guys have put into place for Slackbot to be unique and customized to only the information that each individual user has, only the conversations and the Slack rooms and Slack channels that they're part of—that made my security team sign off rather quickly.\"\nOne Beast Industries employee, Sinan, the head of Beast Games marketing, reported saving \"at bare minimum, 90 minutes a day.\" Another employee, Spencer, a creative supervisor, described it as \"an assistant who's paying attention when I'm not.\"\nOther pilot customers include Slalom, reMarkable, Xero, Mercari, and Engine. Mollie Bodensteiner, SVP of Operations at Engine, called Slackbot \"an absolute 'chaos tamer' for our team,\" estimating it saves her about 30 minutes daily \"just by eliminating context switching.\"\nSlackbot vs. Microsoft Copilot vs. Google Gemini: The fight for enterprise AI dominance\nThe launch puts Salesforce in direct competition with Microsoft's Copilot, which is integrated into Teams and the broader Microsoft 365 suite, as well as Google's Gemini integrations across Workspace. When asked what distinguishes Slackbot from these alternatives, Seaman pointed to context and convenience.\n\"The thing that makes it most powerful for our customers and users is the proximity — it's just right there in your Slack,\" Seaman said. \"There's a tremendous convenience affordance that's naturally built into it.\"\nThe deeper advantage, executives argue, is that Slackbot already understands users' work without requiring setup or training. \"Most AI tools sound the same no matter who is using them,\" the company's announcement stated. \"They lack context, miss nuance, and force you to jump between tools to get anything done.\"\nHarris put it more directly: \"If you've ever had that magic experience with AI — I think ChatGPT is a great example, it's a great experience from a consumer perspective — Slackbot is really what we're doing in the enterprise, to be this employee super agent that is loved, just like people love using Slack.\"\nAmy Bauer emphasized the frictionless nature of the experience. \"Slackbot is inherently grounded in the context, in the data that you have in Slack,\" she said. \"So as you continue working in Slack, Slackbot gets better because it's grounded in the work that you're doing there. There is no setup. There is no configuration for those end users.\"\nSalesforce's ambitious plan to make Slackbot the one 'super agent' that controls all the others\nSalesforce positions Slackbot as what Harris calls a \"super agent\" — a central hub that can eventually coordinate with other AI agents across an organization.\n\"Every corporation is going to have an employee super agent,\" Harris said. \"Slackbot is essentially taking the magic of what Slack does. We think that Slackbot, and we're really excited about it, is going to be that.\"\nThe vision extends to third-party agents already launching in Slack. Last month, Anthropic released a preview of Claude Code for Slack, allowing developers to interact with Claude's coding capabilities directly in chat threads. OpenAI, Google, Vercel, and others have also built agents for the platform.\n\"Most of the net-new apps that are being deployed to Slack are agents,\" Seaman noted during the press conference. \"This is proof of the promise of humans and agents coexisting and working together in Slack to solve problems.\"\nHarris described a future where Slackbot becomes an MCP (Model Context Protocol) client, able to leverage tools from across the software ecosystem — similar to how the developer tool Cursor works. \"Slack can be an MCP client, and Slackbot will be the hub of that, leveraging all these tools out in the world, some of which will be these amazing agents,\" he said.\nBut Harris also cautioned against over-promising on multi-agent coordination. \"I still think we're in the single agent world,\" he said. \"FY26 is going to be the year where we started to see more coordination. But we're going to do it with customer success in mind, and not demonstrate and talk about, like, 'I've got 1,000 agents working together,' because I think that's unrealistic.\"\nSlackbot costs nothing extra, but Salesforce's data access fees could squeeze some customers\nSlackbot is included at no additional cost for customers on Business+ and Enterprise+ plans. \"There's no additional fees customers have to do,\" Gavin confirmed. \"If they're on one of those plans, they're going to get Slackbot.\"\nHowever, some enterprise customers may face other cost pressures related to Salesforce's broader data strategy. CIOs may see price increases for third-party applications that work with Salesforce data, as effects of higher charges for API access ripple through the software supply chain.\nFivetran CEO George Fraser has warned that Salesforce's shift in pricing policy for API access could have tangible consequences for enterprises relying on Salesforce as a system of record. \"They might not be able to use Fivetran to replicate their data to Snowflake and instead have to use Salesforce Data Cloud. Or they might find that they are not able to interact with their data via ChatGPT, and instead have to use Agentforce,\" Fraser said in a recent CIO report.\nSalesforce has framed the pricing change as standard industry practice.\nWhat Slackbot can do today, what's coming in weeks, and what's still on the roadmap\nThe new Slackbot begins rolling out today and will reach all eligible customers by the end of February. Mobile availability will complete by March 3, Bauer confirmed during her interview with VentureBeat.\nSome capabilities remain works in progress. Calendar reading and availability checking are available at launch, but the ability to actually book meetings is \"coming a few weeks after,\" according to Seaman. Image generation is not currently supported, though Bauer said it's \"something that we are looking at in the future.\"\nWhen asked about integration with competing CRM systems like HubSpot and Microsoft Dynamics, Salesforce representatives declined to provide specifics during the interview, though they acknowledged the question touched on key competitive differentiators.\nSalesforce is betting the future of work looks like a chat window—and it's not alone\nThe Slackbot launch is Salesforce's bet that the future of enterprise work is conversational — that employees will increasingly prefer to interact with AI through natural language rather than navigating traditional software interfaces.\nHarris described Slack's product philosophy using principles like \"don't make me think\" and \"be a great host.\" The goal, he said, is for Slackbot to surface information proactively rather than requiring users to hunt for it.\n\"One of the revelations for me is LLMs applied to unstructured information are incredible,\" Harris said. \"And the amount of value you have if you're a Slack user, if your corporation uses Slack — the amount of value in Slack is unbelievable. Because you're talking about work, you're sharing documents, you're making decisions, but you can't as a human go through that and really get the same value that an LLM can do.\"\nLooking ahead, Harris expects the interfaces themselves to evolve beyond pure conversation. \"We're kind of saturating what we can do with purely conversational UIs,\" he said. \"I think we'll start to see agents building an interface that best suits your intent, as opposed to trying to surface something within a conversational interface that matches your intent.\"\nMicrosoft, Google, and a growing roster of AI startups are placing similar bets — that the winning enterprise AI will be the one embedded in the tools workers already use, not another application to learn. The race to become that invisible layer of workplace intelligence is now fully underway.\nFor Salesforce, the stakes extend beyond a single product launch. After a bruising year on Wall Street and persistent questions about whether AI threatens its core business, the company is wagering that Slackbot can prove the opposite — that the tens of millions of people already chatting in Slack every day is not a vulnerability, but an unassailable advantage.\nHaley Gault, the Salesforce account executive in Pittsburgh who stumbled upon the new Slackbot on a snowy morning, captured the shift in a single sentence: \"I honestly can't imagine working for another company not having access to these types of tools. This is just how I work now.\"\nThat's precisely what Salesforce is counting on.",
    "pubDate": "Tue, 13 Jan 2026 13:00:00 GMT",
    "source": "AI | VentureBeat"
  },
  {
    "title": "Anthropic launches Cowork, a Claude Desktop agent that works in your files — no coding required",
    "link": "https://venturebeat.com/technology/anthropic-launches-cowork-a-claude-desktop-agent-that-works-in-your-files-no",
    "description": "Anthropic released Cowork on Monday, a new AI agent capability that extends the power of its wildly successful Claude Code tool to non-technical users — and according to company insiders, the team built the entire feature in approximately a week and a half, largely using Claude Code itself.\nThe launch marks a major inflection point in the race to deliver practical AI agents to mainstream users, positioning Anthropic to compete not just with OpenAI and Google in conversational AI, but with Microsoft's Copilot in the burgeoning market for AI-powered productivity tools.\n\"Cowork lets you complete non-technical tasks much like how developers use Claude Code,\" the company announced via its official Claude account on X. The feature arrives as a research preview available exclusively to Claude Max subscribers — Anthropic's power-user tier priced between $100 and $200 per month — through the macOS desktop application.\nFor the past year, the industry narrative has focused on large language models that can write poetry or debug code. With Cowork, Anthropic is betting that the real enterprise value lies in an AI that can open a folder, read a messy pile of receipts, and generate a structured expense report without human hand-holding.\n\nHow developers using a coding tool for vacation research inspired Anthropic's latest product\nThe genesis of Cowork lies in Anthropic's recent success with the developer community. In late 2024, the company released Claude Code, a terminal-based tool that allowed software engineers to automate rote programming tasks. The tool was a hit, but Anthropic noticed a peculiar trend: users were forcing the coding tool to perform non-coding labor.\nAccording to Boris Cherny, an engineer at Anthropic, the company observed users deploying the developer tool for an unexpectedly diverse array of tasks.\n\n\"Since we launched Claude Code, we saw people using it for all sorts of non-coding work: doing vacation research, building slide decks, cleaning up your email, cancelling subscriptions, recovering wedding photos from a hard drive, monitoring plant growth, controlling your oven,\" Cherny wrote on X. \"These use cases are diverse and surprising — the reason is that the underlying Claude Agent is the best agent, and Opus 4.5 is the best model.\"\nRecognizing this shadow usage, Anthropic effectively stripped the command-line complexity from their developer tool to create a consumer-friendly interface. In its blog post announcing the feature, Anthropic explained that developers \"quickly began using it for almost everything else,\" which \"prompted us to build Cowork: a simpler way for anyone — not just developers — to work with Claude in the very same way.\"\nInside the folder-based architecture that lets Claude read, edit, and create files on your computer\nUnlike a standard chat interface where a user pastes text for analysis, Cowork requires a different level of trust and access. Users designate a specific folder on their local machine that Claude can access. Within that sandbox, the AI agent can read existing files, modify them, or create entirely new ones.\nAnthropic offers several illustrative examples: reorganizing a cluttered downloads folder by sorting and intelligently renaming each file, generating a spreadsheet of expenses from a collection of receipt screenshots, or drafting a report from scattered notes across multiple documents.\n\"In Cowork, you give Claude access to a folder on your computer. Claude can then read, edit, or create files in that folder,\" the company explained on X. \"Try it to create a spreadsheet from a pile of screenshots, or produce a first draft from scattered notes.\"\n\nThe architecture relies on what is known as an \"agentic loop.\" When a user assigns a task, the AI does not merely generate a text response. Instead, it formulates a plan, executes steps in parallel, checks its own work, and asks for clarification if it hits a roadblock. Users can queue multiple tasks and let Claude process them simultaneously — a workflow Anthropic describes as feeling \"much less like a back-and-forth and much more like leaving messages for a coworker.\"\nThe system is built on Anthropic's Claude Agent SDK, meaning it shares the same underlying architecture as Claude Code. Anthropic notes that Cowork \"can take on many of the same tasks that Claude Code can handle, but in a more approachable form for non-coding tasks.\"\nThe recursive loop where AI builds AI: Claude Code reportedly wrote much of Claude Cowork\nPerhaps the most remarkable detail surrounding Cowork's launch is the speed at which the tool was reportedly built — highlighting a recursive feedback loop where AI tools are being used to build better AI tools.\nDuring a livestream hosted by Dan Shipper, Felix Rieseberg, an Anthropic employee, confirmed that the team built Cowork in approximately a week and a half.\nAlex Volkov, who covers AI developments, expressed surprise at the timeline: \"Holy shit Anthropic built 'Cowork' in the last... week and a half?!\"\n\nThis prompted immediate speculation about how much of Cowork was itself built by Claude Code. Simon Smith, EVP of Generative AI at Klick Health, put it bluntly on X: \"Claude Code wrote all of Claude Cowork. Can we all agree that we're in at least somewhat of a recursive improvement loop here?\"\nThe implication is profound: Anthropic's AI coding agent may have substantially contributed to building its own non-technical sibling product. If true, this is one of the most visible examples yet of AI systems being used to accelerate their own development and expansion — a strategy that could widen the gap between AI labs that successfully deploy their own agents internally and those that do not.\nConnectors, browser automation, and skills extend Cowork's reach beyond the local file system\nCowork doesn't operate in isolation. The feature integrates with Anthropic's existing ecosystem of connectors — tools that link Claude to external information sources and services such as Asana, Notion, PayPal, and other supported partners. Users who have configured these connections in the standard Claude interface can leverage them within Cowork sessions.\nAdditionally, Cowork can pair with Claude in Chrome, Anthropic's browser extension, to execute tasks requiring web access. This combination allows the agent to navigate websites, click buttons, fill forms, and extract information from the internet — all while operating from the desktop application.\n\"Cowork includes a number of novel UX and safety features that we think make the product really special,\" Cherny explained, highlighting \"a built-in VM [virtual machine] for isolation, out of the box support for browser automation, support for all your claude.ai data connectors, asking you for clarification when it's unsure.\"\nAnthropic has also introduced an initial set of \"skills\" specifically designed for Cowork that enhance Claude's ability to create documents, presentations, and other files. These build on the Skills for Claude framework the company announced in October, which provides specialized instruction sets Claude can load for particular types of tasks.\nWhy Anthropic is warning users that its own AI agent could delete their files\nThe transition from a chatbot that suggests edits to an agent that makes edits introduces significant risk. An AI that can organize files can, theoretically, delete them.\nIn a notable display of transparency, Anthropic devoted considerable space in its announcement to warning users about Cowork's potential dangers — an unusual approach for a product launch.\nThe company explicitly acknowledges that Claude \"can take potentially destructive actions (such as deleting local files) if it's instructed to.\" Because Claude might occasionally misinterpret instructions, Anthropic urges users to provide \"very clear guidance\" about sensitive operations.\nMore concerning is the risk of prompt injection attacks — a technique where malicious actors embed hidden instructions in content Claude might encounter online, potentially causing the agent to bypass safeguards or take harmful actions.\n\"We've built sophisticated defenses against prompt injections,\" Anthropic wrote, \"but agent safety — that is, the task of securing Claude's real-world actions — is still an active area of development in the industry.\"\nThe company characterized these risks as inherent to the current state of AI agent technology rather than unique to Cowork. \"These risks aren't new with Cowork, but it might be the first time you're using a more advanced tool that moves beyond a simple conversation,\" the announcement notes.\nAnthropic's desktop agent strategy sets up a direct challenge to Microsoft Copilot\nThe launch of Cowork places Anthropic in direct competition with Microsoft, which has spent years attempting to integrate its Copilot AI into the fabric of the Windows operating system with mixed adoption results.\nHowever, Anthropic's approach differs in its isolation. By confining the agent to specific folders and requiring explicit connectors, they are attempting to strike a balance between the utility of an OS-level agent and the security of a sandboxed application.\nWhat distinguishes Anthropic's approach is its bottom-up evolution. Rather than designing an AI assistant and retrofitting agent capabilities, Anthropic built a powerful coding agent first — Claude Code — and is now abstracting its capabilities for broader audiences. This technical lineage may give Cowork more robust agentic behavior from the start.\nClaude Code has generated significant enthusiasm among developers since its initial launch as a command-line tool in late 2024. The company expanded access with a web interface in October 2025, followed by a Slack integration in December. Cowork is the next logical step: bringing the same agentic architecture to users who may never touch a terminal.\nWho can access Cowork now, and what's coming next for Windows and other platforms\nFor now, Cowork remains exclusive to Claude Max subscribers using the macOS desktop application. Users on other subscription tiers — Free, Pro, Team, or Enterprise — can join a waitlist for future access.\nAnthropic has signaled clear intentions to expand the feature's reach. The blog post explicitly mentions plans to add cross-device sync and bring Cowork to Windows as the company learns from the research preview.\nCherny set expectations appropriately, describing the product as \"early and raw, similar to what Claude Code felt like when it first launched.\"\nTo access Cowork, Max subscribers can download or update the Claude macOS app and click on \"Cowork\" in the sidebar.\nThe real question facing enterprise AI adoption\nFor technical decision-makers, the implications of Cowork extend beyond any single product launch. The bottleneck for AI adoption is shifting — no longer is model intelligence the limiting factor, but rather workflow integration and user trust.\nAnthropic's goal, as the company puts it, is to make working with Claude feel less like operating a tool and more like delegating to a colleague. Whether mainstream users are ready to hand over folder access to an AI that might misinterpret their instructions remains an open question.\nBut the speed of Cowork's development — a major feature built in ten days, possibly by the company's own AI — previews a future where the capabilities of these systems compound faster than organizations can evaluate them. \nThe chatbot has learned to use a file manager. What it learns to use next is anyone's guess.",
    "pubDate": "Mon, 12 Jan 2026 11:30:00 GMT",
    "source": "AI | VentureBeat"
  }
]